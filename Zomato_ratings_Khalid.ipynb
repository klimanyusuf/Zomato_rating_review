{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using NLP and machine learning, make a model to predict the rating in a review based on the content of the text review. This will help identify cases with a mismatch.\n",
    "\n",
    "Problem Statement:  \n",
    "\n",
    "Zomato is Indiaâ€™s largest platform for discovering restaurants and ordering food. It operates in India as well as a few cities internationally. Bangalore is one of the biggest customers and restaurant bases for Zomato with 4 to 5 million users using the platform each month.\n",
    "\n",
    "Users on the platform can also post reviews of restaurants and provide a rating accompanying the review. The content in the reviews should ideally reflect the rating provided by the customer. In many cases, there is a mismatch, owing to multiple reasons, where the rating does not match the customer review. The reviews and rating match is very important as it builds customer trust on the platform and helps the user get an accurate picture of the restaurant. \n",
    "\n",
    "You, as a data scientist, need to enable the identification and cleanup of such cases to ensure the ratings reflect the reviews and that the reviews seem trustworthy to the customer. You will need to use NLP techniques in conjunction with machine learning models to predict the rating from the review text. \n",
    "\n",
    "Domain: Hospitality and internet\n",
    "\n",
    "Analysis to be done: Perform specific data cleanup, build a rating prediction model using the Random Forest technique and NLP. \n",
    "\n",
    "Content: \n",
    "\n",
    "rating: the rating given by the customer\n",
    "\n",
    "review_text: the text in the review\n",
    "\n",
    "Steps to perform:\n",
    "\n",
    "Perform clean up on the data; tweak the stop words (negative terms are important). Follow up with a Random Forest Regressor to predict the star rating given by the customers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data using read_csv function from pandas package\n",
    "    Null values in the review text? \n",
    "    Remove the records where the review text is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required Libraries\n",
    "import pandas as pd, numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "rvw = pd.read_csv('C:\\\\dataset\\\\Zomato_reviews.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Their service is worst, pricing in menu is dif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>really appreciate their quality and timing . I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Went there on a Friday night, the place was su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>A very decent place serving good food.\\r\\nOrde...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>One of the BEST places for steaks in the city....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Really lovely place for steaks and sizzlers. T...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5.0</td>\n",
       "      <td>This place ia for ultimate steak lovers!\\r\\nBo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>It's a shame if you haven't tried Once Upon a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.0</td>\n",
       "      <td>We visited this place after we were tired and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Went there for yesterday dinner. Surprisingly ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                        review_text\n",
       "0     1.0  Their service is worst, pricing in menu is dif...\n",
       "1     5.0  really appreciate their quality and timing . I...\n",
       "2     4.0  Went there on a Friday night, the place was su...\n",
       "3     4.0  A very decent place serving good food.\\r\\nOrde...\n",
       "4     5.0  One of the BEST places for steaks in the city....\n",
       "5     5.0  Really lovely place for steaks and sizzlers. T...\n",
       "6     5.0  This place ia for ultimate steak lovers!\\r\\nBo...\n",
       "7     5.0  It's a shame if you haven't tried Once Upon a ...\n",
       "8     4.0  We visited this place after we were tired and ...\n",
       "9     5.0  Went there for yesterday dinner. Surprisingly ..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvw.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>27762.000000</td>\n",
       "      <td>27748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>10548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.665784</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.284573</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rating review_text\n",
       "count   27762.000000       27748\n",
       "unique           NaN       10548\n",
       "top              NaN        good\n",
       "freq             NaN         278\n",
       "mean        3.665784         NaN\n",
       "std         1.284573         NaN\n",
       "min         1.000000         NaN\n",
       "25%         3.000000         NaN\n",
       "50%         4.000000         NaN\n",
       "75%         5.000000         NaN\n",
       "max         5.000000         NaN"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvw.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating          0\n",
       "review_text    14\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rvw.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can see that we have 14 missing values, so we need to get rid of them\n",
    "reviews = rvw[~rvw.review_text.isnull()].copy()\n",
    "reviews.reset_index(inplace=True,drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((27762, 2), (27748, 2))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the changes in size made\n",
    "rvw.shape,reviews.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Converting to list for easy manipulation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_list = reviews.review_text.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27748"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(review_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text clean up\n",
    "\n",
    "    Normalize the case\n",
    "    Remove stop words\n",
    "    remove \"not\", \"no\" from the stop word list\n",
    "    Remove punctuations\n",
    "\n",
    "Normalizing case\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_lower = [txt.lower() for txt in review_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['went there on a friday night, the place was surprisingly empty. interesting menu which is almost fully made of dosas. i had bullseye dosa and cheese masala dosa. the bullseye dosa was really good, with the egg perfectly cooked to a half boiled state. the masala in the cheese masala was good, but the cheese was a bit too chewy for my liking. the chutney was good, the sambar was average. the dishes are reasonably priced.',\n",
       " 'a very decent place serving good food.\\r\\nordered chilli fish, chicken & pork sizzler.\\r\\neverything tasted good but pork could have been slightly better cooked.\\r\\ntried 2 beverages, both were very sweet.']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_lower [2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove extra line breaks**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_lower = [' '.join(txt.split())for txt in reviews_lower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['went there on a friday night, the place was surprisingly empty. interesting menu which is almost fully made of dosas. i had bullseye dosa and cheese masala dosa. the bullseye dosa was really good, with the egg perfectly cooked to a half boiled state. the masala in the cheese masala was good, but the cheese was a bit too chewy for my liking. the chutney was good, the sambar was average. the dishes are reasonably priced.',\n",
       " 'a very decent place serving good food. ordered chilli fish, chicken & pork sizzler. everything tasted good but pork could have been slightly better cooked. tried 2 beverages, both were very sweet.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_lower [2:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tokenize**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['their', 'service', 'is', 'worst', ',', 'pricing', 'in', 'menu', 'is', 'different', 'from', 'bill', '.', 'they', 'can', 'give', 'you', 'a', 'bill', 'with', 'increased', 'pricing', '.', 'even', 'for', 'serving', 'water', ',', 'menu', ',', 'order', 'you', 'need', 'to', 'call', 'them', '3-4', 'times', 'even', 'on', 'a', 'non', 'busy', 'day', '.']\n"
     ]
    }
   ],
   "source": [
    "print(word_tokenize(reviews_lower[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_token = [word_tokenize(sent) for sent in reviews_lower]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['their', 'service', 'is', 'worst', ',', 'pricing', 'in', 'menu', 'is', 'different', 'from', 'bill', '.', 'they', 'can', 'give', 'you', 'a', 'bill', 'with', 'increased', 'pricing', '.', 'even', 'for', 'serving', 'water', ',', 'menu', ',', 'order', 'you', 'need', 'to', 'call', 'them', '3-4', 'times', 'even', 'on', 'a', 'non', 'busy', 'day', '.']\n"
     ]
    }
   ],
   "source": [
    "print(reviews_token[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove Stopwords and Punctuations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_nltk = stopwords.words('english')\n",
    "stop_punct = list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stop_nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_nltk.remove(\"no\")\n",
    "stop_nltk.remove(\"not\")\n",
    "stop_nltk.remove(\"don\")\n",
    "stop_nltk.remove(\"won\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"no\" in stop_nltk #checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_final = stop_nltk + stop_punct + [\"...\" \"``\",\"''\",\"====\", \"must\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_stop (sent):\n",
    "    return [term for term in sent if term not in stop_final]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['really',\n",
       " 'appreciate',\n",
       " 'quality',\n",
       " 'timing',\n",
       " 'tried',\n",
       " 'thattil',\n",
       " 'kutti',\n",
       " 'dosa',\n",
       " \"'ve\",\n",
       " 'addicted',\n",
       " 'dosa',\n",
       " 'really',\n",
       " 'chutney',\n",
       " '...',\n",
       " 'really',\n",
       " 'good',\n",
       " 'money',\n",
       " 'worth',\n",
       " 'much',\n",
       " 'better',\n",
       " 'thattukada',\n",
       " 'try']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del_stop(reviews_token[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_clean = [del_stop(sent)for sent in reviews_token]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['service worst pricing menu different bill give bill increased pricing even serving water menu order need call 3-4 times even non busy day',\n",
       " \"really appreciate quality timing tried thattil kutti dosa 've addicted dosa really chutney ... really good money worth much better thattukada try\"]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_clean = [\" \".join(sent) for sent in reviews_clean]\n",
    "reviews_clean[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate X and Y and perform train test split, 70-30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27748"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = reviews_clean\n",
    "y = reviews.rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train Split Test**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Term Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(max_features = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19423, 8325)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train),len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_bow = vectorizer.fit_transform(X_train)\n",
    "X_test_bow = vectorizer.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((19423, 5000), (8325, 5000))"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow.shape,X_test_bow.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "?RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_rf =RandomForestRegressor(random_state =42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 41min 44s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "learner_rf.fit(X_train_bow,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds = learner_rf.predict(X_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2373941606400989"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_preds)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increase the number of Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_rf = RandomForestRegressor(random_state=42, n_estimators=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=20, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "learner_rf.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_preds =learner_rf.predict(X_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.25058964549391705"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train, y_train_preds)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameter tuning**\n",
    "\n",
    "\"class_weights\" was one of the many hyperparameters to tune for the SVM.\n",
    "\n",
    "Let's find the best hyper-parameters for the SVM classifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "?RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the learner with a random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_rf = RandomForestRegressor(random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the parameter grid based on the results of the random search\n",
    "param_grid = {\n",
    "    'max_features':[500,\"sqrt\",\"log2\",\"auto\"],\n",
    "    'max_depth':[10,15,20,25]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator=learner_rf,param_grid =param_grid,\n",
    "                          cv = 5, n_jobs = -1,scoring= \"neg_mean_squared_error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=RandomForestRegressor(bootstrap=True, ccp_alpha=0.0,\n",
       "                                             criterion='mse', max_depth=None,\n",
       "                                             max_features='auto',\n",
       "                                             max_leaf_nodes=None,\n",
       "                                             max_samples=None,\n",
       "                                             min_impurity_decrease=0.0,\n",
       "                                             min_impurity_split=None,\n",
       "                                             min_samples_leaf=1,\n",
       "                                             min_samples_split=2,\n",
       "                                             min_weight_fraction_leaf=0.0,\n",
       "                                             n_estimators=100, n_jobs=None,\n",
       "                                             oob_score=False, random_state=42,\n",
       "                                             verbose=0, warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'max_depth': [10, 15, 20, 25],\n",
       "                         'max_features': [500, 'sqrt', 'log2', 'auto']},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(X_train_bow, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([ 37.07236056,   6.74747071,   4.00827436, 228.57270694,\n",
       "         58.44549866,   9.62248921,   4.2603394 , 395.91354375,\n",
       "         89.27541137,  14.44212952,   5.60900841, 564.3533114 ,\n",
       "        138.09019222,  30.69729834,   8.36399117, 706.30278912]),\n",
       " 'std_fit_time': array([2.98560762e+00, 8.40883983e-01, 4.36096438e-01, 7.68520732e+00,\n",
       "        3.18194891e+00, 1.35634405e-01, 1.63885210e-01, 7.27190027e+00,\n",
       "        8.94719273e-01, 2.43631788e-01, 7.34954741e-02, 1.18547158e+01,\n",
       "        2.75796845e+01, 6.73438173e+00, 6.90742928e-01, 7.60240893e+01]),\n",
       " 'mean_score_time': array([0.55898051, 0.46547151, 0.56463108, 0.38365803, 0.41605802,\n",
       "        0.41518121, 0.41287847, 0.45065603, 0.4473959 , 0.45915704,\n",
       "        0.41586781, 0.51879048, 0.53820357, 0.60745482, 0.54310079,\n",
       "        0.82014461]),\n",
       " 'std_score_time': array([0.16762087, 0.03572358, 0.08233651, 0.05731684, 0.0417932 ,\n",
       "        0.0178746 , 0.02596757, 0.05728332, 0.0285697 , 0.05432699,\n",
       "        0.01114991, 0.1781424 , 0.06074258, 0.21783119, 0.12926552,\n",
       "        0.62378042]),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 15, 15, 15, 15, 20, 20, 20, 20, 25, 25,\n",
       "                    25, 25],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=[500, 'sqrt', 'log2', 'auto', 500, 'sqrt', 'log2',\n",
       "                    'auto', 500, 'sqrt', 'log2', 'auto', 500, 'sqrt',\n",
       "                    'log2', 'auto'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 10, 'max_features': 500},\n",
       "  {'max_depth': 10, 'max_features': 'sqrt'},\n",
       "  {'max_depth': 10, 'max_features': 'log2'},\n",
       "  {'max_depth': 10, 'max_features': 'auto'},\n",
       "  {'max_depth': 15, 'max_features': 500},\n",
       "  {'max_depth': 15, 'max_features': 'sqrt'},\n",
       "  {'max_depth': 15, 'max_features': 'log2'},\n",
       "  {'max_depth': 15, 'max_features': 'auto'},\n",
       "  {'max_depth': 20, 'max_features': 500},\n",
       "  {'max_depth': 20, 'max_features': 'sqrt'},\n",
       "  {'max_depth': 20, 'max_features': 'log2'},\n",
       "  {'max_depth': 20, 'max_features': 'auto'},\n",
       "  {'max_depth': 25, 'max_features': 500},\n",
       "  {'max_depth': 25, 'max_features': 'sqrt'},\n",
       "  {'max_depth': 25, 'max_features': 'log2'},\n",
       "  {'max_depth': 25, 'max_features': 'auto'}],\n",
       " 'split0_test_score': array([-0.8519572 , -1.20794309, -1.46906749, -0.88011318, -0.6849383 ,\n",
       "        -1.05407152, -1.39031245, -0.71949962, -0.56797786, -0.92406979,\n",
       "        -1.31713505, -0.60789412, -0.48909984, -0.80888487, -1.24481198,\n",
       "        -0.53278936]),\n",
       " 'split1_test_score': array([-0.8435218 , -1.19687493, -1.47864205, -0.80678103, -0.66455867,\n",
       "        -1.03530479, -1.39852061, -0.64954914, -0.54815439, -0.90294494,\n",
       "        -1.32568736, -0.54742658, -0.46193464, -0.78832731, -1.24875626,\n",
       "        -0.46974915]),\n",
       " 'split2_test_score': array([-0.82799005, -1.20698842, -1.49331671, -0.81259077, -0.6510604 ,\n",
       "        -1.04604098, -1.40863518, -0.65242263, -0.53064197, -0.90805954,\n",
       "        -1.3399567 , -0.55295779, -0.45359904, -0.78488316, -1.26527229,\n",
       "        -0.48183944]),\n",
       " 'split3_test_score': array([-0.77587507, -1.11669758, -1.39401772, -0.78997591, -0.61181794,\n",
       "        -0.96588298, -1.31512997, -0.64947024, -0.50601785, -0.84226275,\n",
       "        -1.24227033, -0.55465103, -0.43462425, -0.73467848, -1.17015905,\n",
       "        -0.49026523]),\n",
       " 'split4_test_score': array([-0.81383281, -1.18192869, -1.47141081, -0.79708912, -0.63252186,\n",
       "        -1.02643699, -1.38636892, -0.6530046 , -0.51786082, -0.89177813,\n",
       "        -1.31423441, -0.55322022, -0.44019147, -0.78489204, -1.23993053,\n",
       "        -0.48216508]),\n",
       " 'mean_test_score': array([-0.82263539, -1.18208654, -1.46129096, -0.81731   , -0.64897943,\n",
       "        -1.02554745, -1.37979343, -0.66478925, -0.53413058, -0.89382303,\n",
       "        -1.30785677, -0.56322995, -0.45588985, -0.78033317, -1.23378602,\n",
       "        -0.49136165]),\n",
       " 'std_test_score': array([0.02679066, 0.03400912, 0.03468511, 0.03235245, 0.02526623,\n",
       "        0.03127125, 0.03321989, 0.02739332, 0.02195225, 0.02779711,\n",
       "        0.03399023, 0.02246751, 0.01920081, 0.02451507, 0.03293391,\n",
       "        0.02172467]),\n",
       " 'rank_test_score': array([ 9, 12, 16,  8,  5, 11, 15,  6,  3, 10, 14,  4,  1,  7, 13,  2])}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                      max_depth=25, max_features=500, max_leaf_nodes=None,\n",
       "                      max_samples=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                      random_state=42, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using the best estimator to make predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = grid_search.best_estimator_.predict(X_train_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = grid_search.best_estimator_.predict(X_test_bow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5856532943121"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_train,y_train_pred)**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.389190296697332"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test,y_test_pred)**0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying mismatch cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_df = pd.DataFrame({'review':X_test, 'rating':y_test, 'rating_pred':y_test_pred})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(380, 3)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df[(res_df.rating - res_df.rating_pred)>=2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>rating_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21935</th>\n",
       "      <td>food so..ooooooo tasty excellent flavour order...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.885323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26563</th>\n",
       "      <td>place cozy nice ambience decor cafe really coo...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.440255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27478</th>\n",
       "      <td>food one kind best quality taste good dining e...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.718563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>100 feet road 's new bar one places homes turn...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.918229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15350</th>\n",
       "      <td>food awesome like everything tried chole bhatu...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>2.369793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5593</th>\n",
       "      <td>excellent north indian food dall makhani reall...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.836567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15714</th>\n",
       "      <td>small place nice food decent price try paneer ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.776567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7001</th>\n",
       "      <td>amazing fresh hot tasty worth money</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.879295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5614</th>\n",
       "      <td>okay start ... loved food love service ... yes...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.106383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9469</th>\n",
       "      <td>went sunday brunch located amidst two malls bu...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.913297</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>380 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  review  rating  rating_pred\n",
       "21935  food so..ooooooo tasty excellent flavour order...     5.0     2.885323\n",
       "26563  place cozy nice ambience decor cafe really coo...     5.0     2.440255\n",
       "27478  food one kind best quality taste good dining e...     5.0     2.718563\n",
       "1427   100 feet road 's new bar one places homes turn...     4.0     1.918229\n",
       "15350  food awesome like everything tried chole bhatu...     4.5     2.369793\n",
       "...                                                  ...     ...          ...\n",
       "5593   excellent north indian food dall makhani reall...     4.5     1.836567\n",
       "15714  small place nice food decent price try paneer ...     4.0     1.776567\n",
       "7001                 amazing fresh hot tasty worth money     5.0     2.879295\n",
       "5614   okay start ... loved food love service ... yes...     5.0     2.106383\n",
       "9469   went sunday brunch located amidst two malls bu...     4.0     1.913297\n",
       "\n",
       "[380 rows x 3 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df[(res_df.rating - res_df.rating_pred)>2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
